{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac7ad3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7ec7a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score,classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eae9887",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a88d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = pd.read_csv('data/sample_sub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dfbfab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d6eb013",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pd.read_csv('data/Tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2028c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_COL = 'id'\n",
    "\n",
    "TARGET_COLS = ['Analysis of PDEs', 'Applications',\n",
    "               'Artificial Intelligence', 'Astrophysics of Galaxies',\n",
    "               'Computation and Language', 'Computer Vision and Pattern Recognition',\n",
    "               'Cosmology and Nongalactic Astrophysics',\n",
    "               'Data Structures and Algorithms', 'Differential Geometry',\n",
    "               'Earth and Planetary Astrophysics', 'Fluid Dynamics',\n",
    "               'Information Theory', 'Instrumentation and Methods for Astrophysics',\n",
    "               'Machine Learning', 'Materials Science', 'Methodology', 'Number Theory',\n",
    "               'Optimization and Control', 'Representation Theory', 'Robotics',\n",
    "               'Social and Information Networks', 'Statistics Theory',\n",
    "               'Strongly Correlated Electrons', 'Superconductivity',\n",
    "               'Systems and Control']\n",
    "\n",
    "TOPIC_COLS = ['Computer Science', 'Mathematics', 'Physics', 'Statistics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c446e948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                              0.0\n",
       "ABSTRACT                                        0.0\n",
       "Computer Science                                0.0\n",
       "Mathematics                                     0.0\n",
       "Physics                                         0.0\n",
       "Statistics                                      0.0\n",
       "Analysis of PDEs                                0.0\n",
       "Applications                                    0.0\n",
       "Artificial Intelligence                         0.0\n",
       "Astrophysics of Galaxies                        0.0\n",
       "Computation and Language                        0.0\n",
       "Computer Vision and Pattern Recognition         0.0\n",
       "Cosmology and Nongalactic Astrophysics          0.0\n",
       "Data Structures and Algorithms                  0.0\n",
       "Differential Geometry                           0.0\n",
       "Earth and Planetary Astrophysics                0.0\n",
       "Fluid Dynamics                                  0.0\n",
       "Information Theory                              0.0\n",
       "Instrumentation and Methods for Astrophysics    0.0\n",
       "Machine Learning                                0.0\n",
       "Materials Science                               0.0\n",
       "Methodology                                     0.0\n",
       "Number Theory                                   0.0\n",
       "Optimization and Control                        0.0\n",
       "Representation Theory                           0.0\n",
       "Robotics                                        0.0\n",
       "Social and Information Networks                 0.0\n",
       "Statistics Theory                               0.0\n",
       "Strongly Correlated Electrons                   0.0\n",
       "Superconductivity                               0.0\n",
       "Systems and Control                             0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_values_per_variable = 100 * (train.isnull().sum()/train.shape[0]).round(3)#.reset_index()\n",
    "null_values_per_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c802330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7820d1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we are separating the train data into a train / val data.\n",
    "\n",
    "trn, val = train_test_split(train, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ce0bb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CountVectorizer Model\n",
    "\n",
    "\n",
    "vec = CountVectorizer(max_features=10000)\n",
    "_ = vec.fit(list(train['ABSTRACT']) + list(test['ABSTRACT']))\n",
    "\n",
    "trn_abs = vec.transform(trn['ABSTRACT'])\n",
    "val_abs = vec.transform(val['ABSTRACT'])\n",
    "\n",
    "\n",
    "tst_abs = vec.transform(test['ABSTRACT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6e8faee",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_abs = vec.transform(trn['ABSTRACT'])\n",
    "val_abs = vec.transform(val['ABSTRACT'])\n",
    "tst_abs = vec.transform(test['ABSTRACT'])\n",
    "\n",
    "\n",
    "trn2 = np.hstack((trn_abs.toarray(), trn[TOPIC_COLS]))\n",
    "val2 = np.hstack((val_abs.toarray(), val[TOPIC_COLS]))\n",
    "tst2 = np.hstack((tst_abs.toarray(), test[TOPIC_COLS]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "272e504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "trn2 = csr_matrix(trn2.astype('int16'))\n",
    "val2 = csr_matrix(val2.astype('int16'))\n",
    "tst2 = csr_matrix(tst2.astype('int16'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f62af98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_thresholds(true, preds):\n",
    "  thresholds = [i/100 for i in range(100)]\n",
    "  best_thresholds = []\n",
    "  for idx in range(25):\n",
    "    f1_scores = [f1_score(true[:, idx], (preds[:, idx] > thresh) * 1) for thresh in thresholds]\n",
    "    best_thresh = thresholds[np.argmax(f1_scores)]\n",
    "    best_thresholds.append(best_thresh)\n",
    "  return best_thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "382cf854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7113106372365631"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(LogisticRegression(C = 10, n_jobs=-1))\n",
    "_  = clf.fit(trn2, trn[TARGET_COLS])\n",
    "\n",
    "val_preds = clf.predict_proba(val2)\n",
    "best_thresholds = get_best_thresholds(val[TARGET_COLS].values, val_preds)\n",
    "\n",
    "for i, thresh in enumerate(best_thresholds):\n",
    "  val_preds[:, i] = (val_preds[:, i] > thresh) * 1\n",
    "\n",
    "f1_score(val[TARGET_COLS], val_preds, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aee90e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2801, 25)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9563752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88604b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export pipeline as pickle file\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(clf, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f50dfe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7dbf8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b3d42b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
